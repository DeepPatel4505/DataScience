{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e067fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "%pip install bs4\n",
    "%pip install lxml\n",
    "%pip install pandas\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "options = Options()\n",
    "options.add_argument('--headless')  # optional: runs without opening a browser window\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "59b2c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def convert_to_int(value):\n",
    "    value = value.strip()\n",
    "    if value == '--' or not value:\n",
    "        return 0\n",
    "    try:\n",
    "        if 'K' in value:\n",
    "            return int(float(value.replace('K', '').replace(',', '').strip()) * 1_000)\n",
    "        elif 'L' in value:\n",
    "            return int(float(value.replace('L', '').replace(',', '').strip()) * 100_000)\n",
    "        else:\n",
    "            return int(value.replace(',', ''))\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "print(convert_to_int('--'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "aa906bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 scrapped\n",
      "Page 2 scrapped\n",
      "Page 3 scrapped\n",
      "Page 4 scrapped\n",
      "Page 5 scrapped\n",
      "Page 6 scrapped\n",
      "Page 7 scrapped\n",
      "Page 8 scrapped\n",
      "Page 9 scrapped\n",
      "Page 10 scrapped\n",
      "Page 11 scrapped\n",
      "Page 12 scrapped\n",
      "Page 13 scrapped\n",
      "Page 14 scrapped\n",
      "Page 15 scrapped\n",
      "Page 16 scrapped\n",
      "Page 17 scrapped\n",
      "Page 18 scrapped\n",
      "Page 19 scrapped\n",
      "Page 20 scrapped\n",
      "Page 21 scrapped\n",
      "Page 22 scrapped\n",
      "Page 23 scrapped\n",
      "Page 24 scrapped\n",
      "Page 25 scrapped\n",
      "Page 26 scrapped\n",
      "Page 27 scrapped\n",
      "Page 28 scrapped\n",
      "Page 29 scrapped\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "company_data_list = []\n",
    "for i in range(1,30):\n",
    "        companyData = pd.DataFrame()\n",
    "        companyDetails = soup.find_all('div',class_='companyCardWrapper')\n",
    "\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "        driver.get(f'https://www.ambitionbox.com/list-of-companies?page={i}')\n",
    "\n",
    "        webpage = driver.page_source  # print part of the HTML\n",
    "        driver.quit()\n",
    "        soup = BeautifulSoup(webpage,'lxml')\n",
    "\n",
    "        for company in companyDetails:\n",
    "        # Company Name\n",
    "                companyName = company.find('h2',class_='companyCardWrapper__companyName').text.strip()\n",
    "\n",
    "                # Company Logo\n",
    "                logo = company.find('div',class_='companyCardWrapper__companyLogo')\n",
    "                logoUrl = logo.select_one('img').get_attribute_list('src')[0]\n",
    "\n",
    "                # Rating\n",
    "                rating = float(company.find('div',class_='rating_text').select_one('div').text.strip())\n",
    "\n",
    "                # Industry\n",
    "                industry = company.find('span',class_='companyCardWrapper__interLinking').text.strip()\n",
    "                industry = industry.split(sep='|')\n",
    "                industry = [i.strip() for i in industry]\n",
    "                industryType = industry[0]\n",
    "                \n",
    "                # headquaters\n",
    "                if(len(industry)>1):\n",
    "                        head_locations = industry[1].split(sep='+')\n",
    "                        headquaters = head_locations[0]\n",
    "\n",
    "                        # location_count\n",
    "                        loaction_count = int(head_locations[1].split(sep=' ')[0])\n",
    "\n",
    "                # Rated for \n",
    "                highly_rated_for = []\n",
    "                critically_rated_for = []\n",
    "\n",
    "                rating_blocks = company.find_all('div', class_='companyCardWrapper__ratingComparisonWrapper')\n",
    "                # print(len(rating_blocks))\n",
    "                values = company.find_all('span', class_='companyCardWrapper__ratingValues')\n",
    "                cheader = company.find('span', class_='companyCardWrapper__ratingHeader--critical')\n",
    "                hheader = company.find('span', class_='companyCardWrapper__ratingHeader--high')\n",
    "                if not cheader and hheader:\n",
    "                        highly_rated_for = [i.strip() for i in values[0].text.strip().split(',')]\n",
    "                if not hheader and cheader:\n",
    "                        critically_rated_for = [i.strip() for i in values[0].text.strip().split(',')]\n",
    "                if hheader and cheader:\n",
    "                        highly_rated_for = [i.strip() for i in values[0].text.strip().split(',')]\n",
    "                        critically_rated_for = [i.strip() for i in values[1].text.strip().split(',')]\n",
    "\n",
    "\n",
    "                # Reviews_count\n",
    "                count = company.find_all('a',class_='companyCardWrapper__ActionWrapper')\n",
    "\n",
    "                review_count = count[0].find('span',class_='companyCardWrapper__ActionCount').text\n",
    "                review_count = convert_to_int(review_count)\n",
    "\n",
    "                # salaries_count\n",
    "                salaries_count = count[1].find('span',class_='companyCardWrapper__ActionCount').text\n",
    "                salaries_count = convert_to_int(salaries_count)\n",
    "\n",
    "                # interviews_count\n",
    "                interviews_count = count[2].find('span',class_='companyCardWrapper__ActionCount').text\n",
    "                interviews_count = convert_to_int(interviews_count)\n",
    "\n",
    "                # jobs_count\n",
    "                jobs_count = count[3].find('span',class_='companyCardWrapper__ActionCount').text\n",
    "                jobs_count = convert_to_int(jobs_count)\n",
    "                \n",
    "                company_data_list.append({\n",
    "                        \"Name\": companyName,\n",
    "                        \"Logo\": logoUrl,\n",
    "                        \"Industry Type\": industryType,\n",
    "                        \"Headquarters\": headquaters,\n",
    "                        \"No. of Locations\": loaction_count,\n",
    "                        \"Highly Rated For\": highly_rated_for,\n",
    "                        \"Critically Rated For\": critically_rated_for,\n",
    "                        \"Rating\": rating,\n",
    "                        \"Review Count\": review_count,\n",
    "                        \"Interview Count\": interviews_count,\n",
    "                        \"Salaries Count\": salaries_count,\n",
    "                        \"Job Count\": jobs_count\n",
    "                        })\n",
    "        print(f\"Page {i} scrapped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1468a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "companyData = pd.DataFrame(company_data_list)\n",
    "companyData.head()\n",
    "companyData.to_csv('companies.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
